import warnings
warnings.filterwarnings("ignore")
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from collections import Counter

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score

from imblearn.over_sampling import RandomOverSampler

# Mod√®les
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
import xgboost as xgb


class KidneyDiseaseModelTrainer():
    def __init__(self, file_path, target_col='classification'):
        """
        Initialisation de la classe avec chargement des donn√©es et pr√©traitement.
        """
        self.file_path = file_path
        self.target_col = target_col
        self.models = {
            "Decision Tree": DecisionTreeClassifier(),
            "Random Forest": RandomForestClassifier(),
            "SVM": SVC(),
            "Logistic Regression": LogisticRegression(),
            "KNN": KNeighborsClassifier(),
            "XGBoost": xgb.XGBClassifier()
        }
        self.results = {}

    def load_and_preprocess_data(self):
        """
        Charge et pr√©traite les donn√©es (√©quilibrage, normalisation, r√©duction de dimension).
        """
        # Charger les donn√©es
        data = pd.read_csv(self.file_path)
        
        data = data.drop('Unnamed: 0', axis=1)
        
        print("colonnes:", data.columns)

        # S√©parer les features et la cible
        X = data.drop(columns=[self.target_col])
        y = data[self.target_col]

        # V√©rifier la r√©partition des classes avant √©quilibrage
        print("R√©partition avant √©quilibrage :", Counter(y))


        # Appliquer MinMaxScaler apr√®s √©quilibrage
        scaler = MinMaxScaler(feature_range=(-1, 1))
        X_scaled = scaler.fit_transform(X)

        # S√©parer en ensemble d'entra√Ænement et de test AVANT l'√©quilibrage
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

    def train_and_evaluate(self):
        """
        Entra√Æne plusieurs mod√®les et √©value leurs performances.
        """
        for model_name, model in self.models.items():
            print(f"\nüîπ Entra√Ænement du mod√®le : {model_name}")

            # Entra√Ænement du mod√®le
            model.fit(self.X_train, self.y_train)

            # Pr√©dictions
            y_pred = model.predict(self.X_test)

            # √âvaluation des performances
            accuracy = accuracy_score(self.y_test, y_pred)
            f1 = f1_score(self.y_test, y_pred, average='weighted')  # Calcul du F1-score
            conf_matrix = confusion_matrix(self.y_test, y_pred)
            class_report = classification_report(self.y_test, y_pred)

            # Stocker les r√©sultats
            self.results[model_name] = {
                "accuracy": accuracy,
                "f1_score": f1,
                "confusion_matrix": conf_matrix,
                "classification_report": class_report
            }

            # Affichage des r√©sultats
            print(f"‚úÖ {model_name} - Accuracy: {accuracy:.4f} | F1-score: {f1:.4f}")
            print("\nMatrice de confusion :\n", conf_matrix)
            print("\nRapport de classification :\n", class_report)

    def compare_models(self):
        """
        Compare les mod√®les sur la base de l'accuracy et du f1_score.
        """
        accuracies = {model: res["accuracy"] for model, res in self.results.items()}
        f1_scores = {model: res["f1_score"] for model, res in self.results.items()}

        # Affichage des performances sous forme de graphique
        plt.figure(figsize=(12, 5))

        # Graphique des accuracy
        plt.subplot(1, 2, 1)
        sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette="Blues_r")
        plt.xlabel("Mod√®les")
        plt.ylabel("Accuracy")
        plt.title("Comparaison des mod√®les - Accuracy")
        plt.xticks(rotation=30)

        # Graphique des f1-scores
        plt.subplot(1, 2, 2)
        sns.barplot(x=list(f1_scores.keys()), y=list(f1_scores.values()), palette="Greens_r")
        plt.xlabel("Mod√®les")
        plt.ylabel("F1-score")
        plt.title("Comparaison des mod√®les - F1 Score")
        plt.xticks(rotation=30)

        plt.tight_layout()
        plt.show()

    def get_best_model(self):
        """
        Retourne et sauvegarde le meilleur mod√®le en fonction de l'accuracy et du f1_score.
        """
        best_model = max(self.results, key=lambda k: self.results[k]["f1_score"])
        best_model_instance = self.models[best_model]

        print(f"\nüèÜ Le meilleur mod√®le est : {best_model} avec une Accuracy de {self.results[best_model]['accuracy']:.4f} et un F1-score de {self.results[best_model]['f1_score']:.4f}")

        # Sauvegarde du meilleur mod√®le en .pkl
        model_filename = f"best_model_{best_model}.pkl"
        joblib.dump(best_model_instance, model_filename)
        print(f"üìÅ Mod√®le sauvegard√© sous : {model_filename}")

        return best_model, best_model_instance
    

model = KidneyDiseaseModelTrainer('Final_pre_processing_data.csv')

# Charger et pr√©traiter les donn√©es
model.load_and_preprocess_data()

# Entra√Æner et √©valuer les mod√®les
model.train_and_evaluate()

# Comparer les mod√®les
model.compare_models()

# S√©lectionner le meilleur mod√®le
print("üèÜ Meilleur mod√®le :")
best_model, best_model_instance = model.get_best_model()